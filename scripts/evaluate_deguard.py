__author__ = 'yuanchun'

import os
import argparse
import re
import sys
import difflib

DEFAULT_REPORT_NAME = "deguard_recover_report.txt"
MATCH_MODE_EXACT = "exact"
MATCH_MODE_SIMILAR = "similar"
MATCH_MODE_COMMON_SUBSTR = "common_substr"

RE_CLASS_LINE = re.compile('([^\ ]+) -> ([^\ ]+):\n')
RE_DEGUARD_CLASS_LINE = re.compile('^([^\ ]+) -> ([^\ ]+)\n')
RE_METHOD_LINE = re.compile('([^\ ]+)\ ([^\ ]+)\((.*)\) -> ([^\ ]+)\n')
RE_FIELD_LINE = re.compile('([^\ ]+)\ ([^\ \)]+) -> ([^\ ]+)\n')

RE_SOOT_FIELD = re.compile('<(.+): (.+) (.+)>')
RE_SOOT_METHOD = re.compile('<(.+): (.+) (.+)\((.*)\)>')

class IdentifierMapping(object):
    """
    describe a mapping.txt generated by proguard or UnuglifyDEX
    """
    def __init__(self, mapping_file=None, recovered_derg=None, de_mapping_file=None):
        self.package_mapping = {}
        self.class_mapping = {}
        self.field_mapping = {}
        self.method_mapping = {}

        if mapping_file is not None:
            self.lines = open(mapping_file).readlines()
            self.class_origin2obfus = {}
            self._build_package_class_mapping()
            self._build_field_method_mapping()
        elif recovered_derg is not None:
            import json
            self.derg = json.load(open(recovered_derg, 'r'))
            self.sigs_3lib = set()
            self._build_mapping_from_derg()
        elif de_mapping_file is not None:
            self.lines = open(de_mapping_file).readlines()
            self.class_origin2obfus = {}
            self._build_package_class_de_mapping()
            self._build_field_method_de_mapping()
        else:
            print "No input file specified."
            return

        self.mapping = {}
        self.mapping.update(self.package_mapping)
        self.mapping.update(self.class_mapping)
        self.mapping.update(self.field_mapping)
        self.mapping.update(self.method_mapping)

    def update(self, another_mapping):
        self.package_mapping.update(another_mapping.package_mapping)
        self.class_mapping.update(another_mapping.class_mapping)
        self.field_mapping.update(another_mapping.field_mapping)
        self.method_mapping.update(another_mapping.method_mapping)
        self.mapping.update(another_mapping.mapping)

    def _build_mapping_from_derg(self):
        for node in self.derg['nodes']:
            node_type = node['type']
            node_sig = node['sig']
            node_name = node['name']
            node_recovered_name = node['recovered_name']
            if node_type in ["field", "field_3LIB"]:
                node_sig = self.convert_soot_field_sig_to_unique_id(node_sig)
            elif node_type in ["method", "method_3LIB"]:
                node_sig = self.convert_soot_method_sig_to_unique_id(node_sig)

            if node_name == node_recovered_name:
                continue

            if node_type.endswith("_3LIB"):
                self.sigs_3lib.add(node_sig)

            if node_type in ["package", "package_3LIB"]:
                self.package_mapping[node_sig] = node_recovered_name
            elif node_type in ["class", "class_3LIB"]:
                self.class_mapping[node_sig] = node_recovered_name
            elif node_type in ["field", "field_3LIB"]:
                self.field_mapping[node_sig] = node_recovered_name
            elif node_type in ["method", "method_3LIB"]:
                self.method_mapping[node_sig] = node_recovered_name

    def convert_soot_field_sig_to_unique_id(self, soot_field_sig):
        m = re.match(RE_SOOT_FIELD, soot_field_sig)
        if not m:
            print "warning: illegal soot field."
            return
        cls_sig, field_type, field_name = m.group(1), m.group(2), m.group(3)
        return "%s;->%s:%s" % (cls_sig, field_name, field_type)

    def convert_soot_method_sig_to_unique_id(self, soot_method_sig):
        m = re.match(RE_SOOT_METHOD, soot_method_sig)
        if not m:
            print "warning: illegal soot method."
            return
        cls_sig, ret_type, method_name, para_types = m.group(1), m.group(2), m.group(3), m.group(4)
        return "%s;->%s(%s)" % (cls_sig, method_name, para_types)

    def dump(self, out_file):
        for key in sorted(self.mapping):
            out_file.write("%s -> %s\n" % (key, self.mapping[key]))

    def dump_report(self, file_name):
        out_file = open(file_name, "w")
        self.dump(out_file)
        out_file.close()

    def _build_package_class_mapping(self):
        for line in self.lines:
            m = RE_CLASS_LINE.search(line)
            if not m:
                continue
            class_origin, class_obfus = m.group(1), m.group(2)
            package_origin, package_obfus = \
                ".".join(class_origin.split('.')[:-1]), ".".join(class_obfus.split('.')[:-1])
            self._add_class_map(class_origin, class_obfus)
            self._add_package_map(package_origin, package_obfus)

    def _build_field_method_mapping(self):
        current_cls_id = None
        for line in self.lines:
            m = RE_CLASS_LINE.search(line)
            if m:
                current_cls_id = m.group(2)
                continue
            m = RE_FIELD_LINE.search(line)
            if m:
                # assert current_cls_id is not None
                field_type, origin_name, obfus_name = \
                    m.group(1).strip(), m.group(2).strip(), m.group(3).strip()
                if origin_name == obfus_name:
                    continue
                field_id = self._get_unique_field_id(current_cls_id, obfus_name, field_type)
                # assert field_id not in self.field_mapping.keys()
                self.field_mapping[field_id] = origin_name
                continue
            m = RE_METHOD_LINE.search(line)
            if m:
                # assert current_cls_id is not None
                ret_type, origin_name, param_types, obfus_name = \
                    m.group(1).strip(), m.group(2).strip(), m.group(3).strip(), m.group(4).strip()
                if origin_name == obfus_name:
                    continue
                method_id = self._get_unique_method_id(current_cls_id, obfus_name, param_types)
                # assert method_id not in self.method_mapping.keys()
                self.method_mapping[method_id] = origin_name

    def _build_package_class_de_mapping(self):
        for line in self.lines:
            m = RE_DEGUARD_CLASS_LINE.search(line)
            if not m:
                continue
            class_origin, class_obfus = m.group(2), m.group(1)
            package_origin, package_obfus = \
                ".".join(class_origin.split('.')[:-1]), ".".join(class_obfus.split('.')[:-1])
            self._add_class_map(class_origin, class_obfus)
            self._add_package_map(package_origin, package_obfus)

    def _build_field_method_de_mapping(self):
        current_cls_id = None
        for line in self.lines:
            m = RE_DEGUARD_CLASS_LINE.search(line)
            if m:
                current_cls_id = m.group(1)
                continue
            m = RE_FIELD_LINE.search(line)
            if m:
                # assert current_cls_id is not None
                obfus_field_type, obfus_name, origin_name = \
                    m.group(1).strip(), m.group(2).strip(), m.group(3).strip()
                if origin_name == obfus_name:
                    continue
                field_id = self._get_unique_field_id2(current_cls_id, obfus_name, obfus_field_type)
                # assert field_id not in self.field_mapping.keys()
                self.field_mapping[field_id] = origin_name
                continue
            m = RE_METHOD_LINE.search(line)
            if m:
                # assert current_cls_id is not None
                obfus_ret_type, obfus_name, obfus_param_types, origin_name = \
                    m.group(1).strip(), m.group(2).strip(), m.group(3).strip(), m.group(4).strip()
                if origin_name == obfus_name:
                    continue
                method_id = self._get_unique_method_id2(current_cls_id, obfus_name, obfus_param_types)
                # assert method_id not in self.method_mapping.keys()
                self.method_mapping[method_id] = origin_name

    def _add_class_map(self, class_origin, class_obfus):
        if class_origin == class_obfus:
            return
        self.class_mapping[class_obfus] = class_origin.split('.')[-1]
        self.class_origin2obfus[class_origin] = class_obfus

    def _add_package_map(self, package_origin, package_obfus):
        if package_origin == package_obfus:
            return
        self.package_mapping[package_obfus] = package_origin.split('.')[-1]

    def _get_unique_field_id(self, class_id, obfus_field_name, field_type):
        type_id = self._get_unique_class_id(field_type)
        return "%s;->%s:%s" % (class_id, obfus_field_name, type_id)

    def _get_unique_method_id(self, class_id, obfus_method_name, param_types):
        param_ids = []
        for param_type in param_types.split(','):
            param_ids.append(self._get_unique_class_id(param_type))
        return "%s;->%s(%s)" % (class_id, obfus_method_name, ",".join(param_ids))

    def _get_unique_class_id(self, class_name):
        if class_name in self.class_origin2obfus.keys():
            return self.class_origin2obfus[class_name]
        else:
            return class_name

    def _get_unique_field_id2(self, class_id, obfus_field_name, obfus_field_type):
        type_id = self._get_unique_class_id2(obfus_field_type)
        return "%s;->%s:%s" % (class_id, obfus_field_name, type_id)

    def _get_unique_method_id2(self, class_id, obfus_method_name, obfus_param_types):
        param_ids = []
        for obfus_param_type in obfus_param_types.split(','):
            param_ids.append(self._get_unique_class_id2(obfus_param_type))
        return "%s;->%s(%s)" % (class_id, obfus_method_name, ",".join(param_ids))

    def _get_unique_class_id2(self, obfus_class_name):
        return obfus_class_name


def run(mapping_file, recovered_derg, deguard_mapping_file, match_mode, report_dir, report_name):

    """

    :param mapping_file:
    :param recovered_derg:
    :param report_dir:
    """

    mapping_file = os.path.abspath(mapping_file)
    recovered_derg = os.path.abspath(recovered_derg)
    report_dir = os.path.abspath(report_dir)

    proguard = IdentifierMapping(mapping_file=mapping_file)
    # proguard.dump_report(report_dir + "/minify_result.txt")

    recover = IdentifierMapping(recovered_derg=recovered_derg)
    third_party_sigs = recover.sigs_3lib
    # recover.dump_report(report_dir + "/recover_result.txt")

    if deguard_mapping_file is not None:
        deguard_mapping_file = os.path.abspath(deguard_mapping_file)
        deguard = IdentifierMapping(de_mapping_file=deguard_mapping_file)
        # deguard.update(recover)
        recover = deguard

    dump_statistics(proguard, recover, sys.stdout)
    compare_report = open(os.path.join(report_dir, report_name), "w")
    dump_report(proguard, recover, match_mode, third_party_sigs, compare_report)


def dump_statistics(proguard, predict, out_file):
    output_template = "%d items are minified, %d items are recovered.\n" \
                      "TP: %d, Recall: %f, Precision: %f\n\n"

    out_file.write("For packages:\n" + output_template % compare_two_dict(proguard.package_mapping, predict.package_mapping))
    out_file.write("For classes:\n" + output_template % compare_two_dict(proguard.class_mapping, predict.class_mapping))
    out_file.write("For fields:\n" + output_template % compare_two_dict(proguard.field_mapping, predict.field_mapping))
    out_file.write("For methods:\n" + output_template % compare_two_dict(proguard.method_mapping, predict.method_mapping))
    out_file.write("In total:\n" + output_template % compare_two_dict(proguard.mapping, predict.mapping))


def dump_compare_dict(a, b, match_mode, third_party_sigs, report_file, flag="l"):
    all_keys = set(a.keys()) | set(b.keys())
    for key in sorted(all_keys):
        value_proguard = safe_get(a, key)
        value_predict = safe_get(b, key)
        line_flag = flag if is_matched(value_proguard, value_predict, match_mode) else flag.upper()
        lib_flag = "3LIB" if key in third_party_sigs else "degd"
        report_file.write("[%s](%s) %s %s/%s\n" % (line_flag, lib_flag, key, value_proguard, value_predict))


def dump_report(proguard, predict, match_mode, third_party_sigs, report_file):
    dump_statistics(proguard, predict, report_file)
    report_file.write("\n[f] <Obfuscation> <Origin>/<Prediction>\n"
                      "[f] = flag, P,C,M,F = package,class,method,field. Upper case means mismatch.\n"
                      "--------\n")
    dump_compare_dict(proguard.package_mapping, predict.package_mapping, match_mode, third_party_sigs, report_file, "p")
    dump_compare_dict(proguard.class_mapping, predict.class_mapping, match_mode, third_party_sigs, report_file, "c")
    dump_compare_dict(proguard.field_mapping, predict.field_mapping, match_mode, third_party_sigs, report_file, "f")
    dump_compare_dict(proguard.method_mapping, predict.method_mapping, match_mode, third_party_sigs, report_file, "m")


def longest_common_substring(s1, s2):
    s1 = s1.lower()
    s2 = s2.lower()
    m = [[0] * (1 + len(s2)) for i in xrange(1 + len(s1))]
    longest, x_longest = 0, 0
    for x in xrange(1, 1 + len(s1)):
        for y in xrange(1, 1 + len(s2)):
            if s1[x - 1] == s2[y - 1]:
                m[x][y] = m[x - 1][y - 1] + 1
                if m[x][y] > longest:
                    longest = m[x][y]
                    x_longest = x
            else:
                m[x][y] = 0
    return s1[x_longest - longest: x_longest]


def is_matched(name1, name2, match_mode):
    if name1 == name2:
        return True
    elif match_mode == MATCH_MODE_COMMON_SUBSTR:
        common_substr = longest_common_substring(name1, name2)
        return len(common_substr) >= 3
    elif match_mode == MATCH_MODE_SIMILAR:
        ratio = difflib.SequenceMatcher(a=name1, b=name2).ratio()
        return ratio >= 0.6
    else:
        return False


def safe_get(data_dict, key):
    if key in data_dict.keys():
        return data_dict[key]
    return "?"


def compare_two_dict(dict_a, dict_b):
    set_a = set(dict_a.items())
    set_b = set(dict_b.items())
    set_tp = set_a & set_b
    return (len(set_a), len(set_b), len(set_tp),
            safe_divide(len(set_tp), len(set_a)), safe_divide(len(set_tp), len(set_b)))


def safe_divide(a, b):
    if b <= 0:
        return 1
    return float(a) / b


def parse_args():
    """
    parse command line input
    generate options including input proguard-generated mappings and predict mappings
    """
    parser = argparse.ArgumentParser(description="evaluate the recovered derg by comparing with ground truth mapping file")
    parser.add_argument("-mapping", action="store", dest="mapping_file",
                        required=True, help="path to proguard-generated mapping.txt")
    parser.add_argument("-recovered_derg", action="store", dest="recovered_derg",
                        required=True, help="path to recovered derg")
    parser.add_argument("-deguard_mapping", action="store", dest="deguard_mapping_file",
                        help="path to deguard-generated mapping.txt")
    parser.add_argument("-o", action="store", dest="report_dir",
                        default=".", help="directory of report files")
    parser.add_argument("-report_name", action="store", dest="report_name",
                        default=DEFAULT_REPORT_NAME, help="name of report file")
    parser.add_argument("-match_mode", action="store", dest="match_mode",
                        default=MATCH_MODE_EXACT, help="match mode")

    options = parser.parse_args()
    print options
    return options


def main():
    """
    the main function
    """
    opts = parse_args()
    run(opts.mapping_file, opts.recovered_derg, opts.deguard_mapping_file, opts.match_mode, opts.report_dir, opts.report_name)

    return


if __name__ == "__main__":
    main()
